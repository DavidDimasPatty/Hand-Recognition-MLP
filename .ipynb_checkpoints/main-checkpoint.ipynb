{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb91798",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c262756c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:01:15.186387Z",
     "start_time": "2025-06-30T06:01:15.182328Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee9906e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a0803bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:01:16.080980Z",
     "start_time": "2025-06-30T06:01:16.077437Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=[]\n",
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14174a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:01:23.938949Z",
     "start_time": "2025-06-30T06:01:16.670350Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (5243, 64, 64, 3)\n",
      "Labels shape: (5243,)\n"
     ]
    }
   ],
   "source": [
    "folder_path= \"images\"\n",
    "folders = os.listdir(folder_path)\n",
    "\n",
    "for folder in folders:\n",
    "    pathPerFolder=os.path.join(folder_path,folder);\n",
    "    folderChild= os.listdir(pathPerFolder)\n",
    "    for file in folderChild:\n",
    "        img_path=os.path.join(pathPerFolder,file)\n",
    "        img=cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (64,64))\n",
    "        img= img/255.0\n",
    "        frames=img\n",
    "        data.append(img)\n",
    "        labels.append(folder)\n",
    "        \n",
    "data=np.array(data,dtype=np.float32)\n",
    "labels=np.array(labels)\n",
    "print(f'Data shape: {data.shape}')\n",
    "print(f'Labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab5ca175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:01:28.755078Z",
     "start_time": "2025-06-30T06:01:28.750581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12288\n"
     ]
    }
   ],
   "source": [
    "data[0].shape\n",
    "sp1,sp2,sp3,sp4=data.shape\n",
    "sp2\n",
    "print(sp2*sp3*sp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "008ece4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:01:29.627307Z",
     "start_time": "2025-06-30T06:01:29.612168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7725ea96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:02.832981Z",
     "start_time": "2025-06-30T06:16:02.397242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  rand_index = np.random.randint(0, data.shape[0])\n",
    "  plt.imshow(data[rand_index])\n",
    "  plt.title(\"Ground Truth: {}\".format(labels[rand_index]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb89a442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:03.291980Z",
     "start_time": "2025-06-30T06:16:03.284849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['call_me', 'fingers_crossed', 'okay', 'paper', 'peace', 'rock',\n",
       "       'rock_on', 'scissor', 'thumbs', 'up'], dtype='<U15')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "493b132c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:03.759177Z",
     "start_time": "2025-06-30T06:16:03.733356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['call_me' 'fingers_crossed' 'okay' 'paper' 'peace' 'rock' 'rock_on'\n",
      " 'scissor' 'thumbs' 'up']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapping ke int\n",
    "unique_labels = np.unique(labels)\n",
    "print(unique_labels)\n",
    "mapping = {label: i for i, label in enumerate(unique_labels)}\n",
    "labelsFinal = [mapping[label] for label in labels]\n",
    "\n",
    "#for i in range(len(labels)):\n",
    "#    labelsFinal[i]=labelsFinal[i]/10;\n",
    "    \n",
    "labelsFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c74d99e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:04.373030Z",
     "start_time": "2025-06-30T06:16:04.365798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.tensor(labelsFinal).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97c31c19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:05.039842Z",
     "start_time": "2025-06-30T06:16:04.933149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0039, 0.0039, 0.0039],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0078, 0.0078, 0.0078],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0118, 0.0118, 0.0118],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e83f307",
   "metadata": {},
   "source": [
    "# Modeling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93be11a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:06.257445Z",
     "start_time": "2025-06-30T06:16:06.085390Z"
    }
   },
   "outputs": [],
   "source": [
    "data_tensor = torch.tensor(data)\n",
    "labels_tensor = torch.tensor(labelsFinal)\n",
    "\n",
    "rand_idx = torch.randperm(len(data_tensor))\n",
    "\n",
    "\n",
    "data_tensor = data_tensor[rand_idx]\n",
    "labels_tensor = labels_tensor[rand_idx]\n",
    "\n",
    "\n",
    "x_trains = data_tensor.reshape(-1, sp2*sp3*sp4)\n",
    "y_trains = labels_tensor\n",
    "\n",
    "\n",
    "split = int(0.8*len(x_trains))\n",
    "x_train = x_trains[:split]\n",
    "y_train = y_trains[:split]\n",
    "x_testing = x_trains[split:]\n",
    "y_testing = y_trains[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8dd9637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:06.592398Z",
     "start_time": "2025-06-30T06:16:06.581396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 7, 7,  ..., 4, 5, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca9ae5df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:07.020809Z",
     "start_time": "2025-06-30T06:16:07.011403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377fa60",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f4ccb467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:17:41.109219Z",
     "start_time": "2025-06-30T06:17:41.101645Z"
    }
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,weight,bias):\n",
    "        self.weight=weight;\n",
    "        self.bias=bias;\n",
    "    \n",
    "    def activationSigmoid(self,input) : #Sigmoid\n",
    "        sigmoid = torch.sigmoid(input)\n",
    "        return sigmoid\n",
    "    \n",
    "    def activationRelu(self,input) : #ReLu\n",
    "        m = nn.ReLU()\n",
    "        return m(input)\n",
    "    \n",
    "    def activationSM(self,input) : #SoftMax\n",
    "        #A = torch.exp(input) / torch.sum(torch.exp(input))\n",
    "        #return A\n",
    "        m = nn.Softmax(dim=1)\n",
    "        return m(input)\n",
    "   \n",
    "    def dSigmoid(self,input):\n",
    "        sigmoid=torch.sigmoid(input)\n",
    "        return sigmoid * (1-sigmoid)\n",
    "    \n",
    "    def dRelu(self,input):\n",
    "        return torch.where(input>0,1.0,0.0)\n",
    "    \n",
    "    def dSoftMax(self,input):\n",
    "        sm=torch.softmax(input,dim=1)\n",
    "        return sm * (1-sm)\n",
    "        \n",
    "    def forward1(self, input) :\n",
    "         input = input.float()\n",
    "         output = (torch.matmul(input, self.weight)) + self.bias\n",
    "         return output, self.activationRelu(output)\n",
    "       \n",
    "    def forward2(self, input) :\n",
    "        output=(torch.matmul(input,self.weight))+self.bias\n",
    "        return output,self.activationSigmoid(output)\n",
    "    \n",
    "    def forward3(self, input) :\n",
    "        output=(torch.matmul(input, self.weight)) + self.bias\n",
    "        return output, self.activationSM(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08734d8c",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e967cf02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:10.043030Z",
     "start_time": "2025-06-30T06:16:10.030241Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self,w1,b1,w2,b2,w3,b3,batch_size=10):\n",
    "        self.batch_size=batch_size;\n",
    "        self.w1=w1\n",
    "        self.b1=b1\n",
    "        self.w2=w2\n",
    "        self.b2=b2\n",
    "        self.w3=w3\n",
    "        self.b3=b3\n",
    "        self.layer1=Layer(self.w1,self.b1)\n",
    "        self.layer2=Layer(self.w2,self.b2)\n",
    "        self.layer3=Layer(self.w3,self.b3)\n",
    "        \n",
    "    def forward1(self,x):\n",
    "        pred,a=self.layer1.forward1(x)\n",
    "        return pred,a\n",
    "    \n",
    "    def forward2(self,x):\n",
    "        pred,a=self.layer2.forward2(x)\n",
    "        return pred,a\n",
    "    \n",
    "    def forward3(self,x):\n",
    "        pred,a=self.layer3.forward3(x)\n",
    "        return pred,a\n",
    "    \n",
    "    def backPropLayer3(self,Z1, A1, Z2, A2, A3,W1,W2,W3, X, Y,m):\n",
    "        dZ3=A3-Y;\n",
    "        dW = (1/m) * A2.T @ dZ3\n",
    "        dB = (1/m) * torch.sum(dZ3, dim=0)\n",
    "        return self.backPropLayer2(dZ3,A1,Z1, A2,Z2,W1,W2,W3,X, Y,m,dW,dB);\n",
    "        \n",
    "    def backPropLayer2(self,dZ3,A1,Z1, A2,Z2,W1,W2,W3,X, Y,m,dW3,db3):\n",
    "        dZ2 = (dZ3.float() @ W3.T.float()) * self.layer2.dSigmoid(Z2.float())\n",
    "        dW = (1/m) * A1.T.float() @ dZ2.float()\n",
    "        db = 1 / m * torch.sum(dZ2)\n",
    "        return self.backPropLayer1(dZ2,dZ3,A1,Z1, A2,Z2,W1,W2,X, Y,m,dW3,db3,dW,db)\n",
    "        \n",
    "    def backPropLayer1(self,dZ2,dZ3,A1,Z1, A2,Z2,W1,W2,X, Y,m,dW3,db3,dW2,db2):\n",
    "        dZ1 = (dZ2.float()@W2.T.float()) * self.layer1.dRelu(Z1.float())\n",
    "        dW = (1/m) * X.T.float() @ dZ1.float()\n",
    "        db = 1 / m * torch.sum(dZ1)\n",
    "        return dW, db, dW2, db2, dW3, db3\n",
    "    \n",
    "    def single_processing(self,input):\n",
    "        pred1,error1=self.forward1(input)\n",
    "        pred2,error2=self.forward2(error1)\n",
    "        pred3,error3=self.forward3(error2)\n",
    "        return pred1,error1,pred2,error2,pred3,error3\n",
    "    \n",
    "    def batch_processing(self,input,target):\n",
    "        for i in range(0,len(input)-1,self.batch_size):\n",
    "            new_len = [input[j].tolist() for j in range(i, i+self.batch_size)]\n",
    "            new_ten=torch.Tensor(new_len)\n",
    "            new_tar = [target[j].tolist() for j in range(i, i+self.batch_size)]\n",
    "            new_tar2=torch.Tensor(new_tar)\n",
    "            self.single_processing(new_ten,new_tar2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1030b5db",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "715afdba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:10.986079Z",
     "start_time": "2025-06-30T06:16:10.966331Z"
    }
   },
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self,x_train,y_train,seed=52,learning_rate=0.05,epoch=1000,stop=8):\n",
    "        self.seed=seed\n",
    "        torch.manual_seed(self.seed)\n",
    "        randData=torch.randperm(len(x_train))\n",
    "        self.x_train=x_train[randData];\n",
    "        self.y_train=y_train[randData];\n",
    "        self.m=x_train.shape[1]\n",
    "        self.learning_rate=learning_rate;\n",
    "        self.w1=torch.randn((self.m,512), dtype=torch.float32) * np.sqrt(1./(512))\n",
    "        self.b1=torch.randn((512), dtype=torch.float32) * np.sqrt(1./(512))\n",
    "        self.w2=torch.randn((512,64), dtype=torch.float32) * np.sqrt(1./(64))\n",
    "        self.b2=torch.randn((64), dtype=torch.float32) * np.sqrt(1./(64))\n",
    "        self.w3=torch.randn((64,10), dtype=torch.float32) * np.sqrt(1./(10))\n",
    "        self.b3=torch.randn((10), dtype=torch.float32) * np.sqrt(1./(10))\n",
    "        self.epoch=epoch\n",
    "        self.learning_rate=learning_rate\n",
    "        self.stop=stop\n",
    "        self.model=Network(self.w1,self.b1,self.w2,self.b2,self.w3,self.b3)\n",
    "   \n",
    "    def convertY(self,Y):\n",
    "         Y_res = torch.zeros((len(Y), 10))\n",
    "         Y_res[torch.arange(len(Y)), Y.long()] = 1\n",
    "         return Y_res\n",
    "        \n",
    "    def forward_prop(self,w1,b1,w2,b2,w3,b3,X):\n",
    "        pred1,error1,pred2,error2,pred3,error3=self.model.single_processing(X)\n",
    "        return pred1.double(), error1.double(), pred2.double(), error2.double(), pred3.double(), error3.double()\n",
    "    \n",
    "    def backward_prop(self,Z1, A1, Z2, A2, A3,W1,W2,W3, X, Y):\n",
    "        dW, db, dW2, db2, dW3, db3=self.model.backPropLayer3(Z1, A1, Z2, A2, A3,self.w1,self.w2,self.w3, self.x_train, self.convertY(self.y_train),self.m)\n",
    "        return torch.tensor(dW), torch.tensor(db), torch.tensor(dW2), torch.tensor(db2),torch.tensor(dW3), torch.tensor(db3)\n",
    "    \n",
    "    def update_params(self,W1, b1, W2, b2,W3,b3, dW1, db1, dW2, db2,dW3,db3, alpha):\n",
    "        W1 = W1 - (alpha * dW1)\n",
    "        b1 = b1 - alpha * db1\n",
    "        W2 = W2 - (alpha * dW2)\n",
    "        b2 = b2 - alpha * db2\n",
    "        W3 = W3 - (alpha * dW3)\n",
    "        b3 = b3 - alpha * db3\n",
    "        return W1,b1,W2,b2,W3,b3\n",
    "    \n",
    "    def get_predictions(self,A):\n",
    "        #print(torch.argmax(A, dim=1))\n",
    "        return torch.argmax(A, 0)\n",
    "\n",
    "    def get_accuracy(self,predictions, Y):\n",
    "        return torch.sum(predictions == Y) / self.m\n",
    "    \n",
    "    def trainingData(self):\n",
    "        verge=0;\n",
    "        treshold=0;\n",
    "        for i in range(self.epoch):\n",
    "            Z1,A1,Z2,A2,Z3,A3= self.forward_prop(self.w1,self.b1,self.w2,self.b2,self.w3,self.b3,self.x_train)\n",
    "            dW1, db1, dW2, db2,dW3,db3 = self.backward_prop(Z1, A1, Z2, A2, A3, self.w1,self.w2,self.w3,self.x_train, self.y_train)\n",
    "            self.w1,self.b1,self.w2, self.b2,self.w3,self.b3 = self.update_params(self.w1, self.b1, self.w2, self.b2,self.w3,self.b3, dW1, db1, dW2, db2,dW3,db3, self.learning_rate)\n",
    "            print(f\"Iteration {i}\")\n",
    "            predictions=self.get_predictions(A3.T) \n",
    "            print(f\"Iter {i} | W1 max: {self.w1.max():.4f}, min: {self.w1.min():.4f}\")\n",
    "            print(f\"Iter {i} | A3 max: {A3.max():.4f}, min: {A3.min():.4f}, sum: {A3.sum()}\")\n",
    "            print(f\"Iter {i} | Predictions unique: {predictions.unique(return_counts=True)}\")\n",
    "            print(f\"Coba :{A3.T} dan predict : {predictions.unique()}\")\n",
    "            print(f\"Prediction: {predictions}, Label : {self.y_train}\")\n",
    "            acc=self.get_accuracy(predictions,self.y_train)\n",
    "            print(f\"accuracy : {acc*100}%\")\n",
    "            if(verge>acc):\n",
    "                treshold+=1\n",
    "            else:\n",
    "                verge=acc\n",
    "                treshold=0\n",
    "            if(treshold>=self.stop):\n",
    "                return self.w1,self.b1,self.w2,self.b2,self.w3,self.b3\n",
    "        return self.w1,self.b1,self.w2,self.b2,self.w3,self.b3 \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ed15b",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78b38b76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:11.827853Z",
     "start_time": "2025-06-30T06:16:11.820900Z"
    }
   },
   "outputs": [],
   "source": [
    "class Validation:\n",
    "    def __init__(self,w1,b1,w2,b2,w3,b3,index):\n",
    "        self.w1=w1\n",
    "        self.b1=b1\n",
    "        self.w2=w2\n",
    "        self.b2=b2\n",
    "        self.w3=w3\n",
    "        self.b3=b3\n",
    "        self.index=index\n",
    "        \n",
    "    def predict(self,X):\n",
    "        Z1,A1,Z2,A2,Z3,A3=self.forwardValid(X)\n",
    "        prediction=self.get_prediction_validation(A3)\n",
    "        return prediction\n",
    "    \n",
    "    def forwardValid(self,X):\n",
    "        model= Network(self.w1,self.b1,self.w2,self.b2,self.w3,self.b3)\n",
    "        pred1,error1,pred2,error2,pred3,error3=model.single_processing(X)\n",
    "        return pred1.double(), error1.double(), pred2.double(), error2.double(), pred3.double(), error3.double()\n",
    "    \n",
    "    def get_prediction_validation(self,A):\n",
    "        return torch.argmax(A, 0)\n",
    "            \n",
    "    def ValidationMain(self):\n",
    "        imageValid=x_testing[index,:,None]\n",
    "        prediction=self.predict(X)\n",
    "        label=y_testing[index]\n",
    "        print(f\"Hasil : {prediction}, Data Asli : {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac2065",
   "metadata": {},
   "source": [
    "# Start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "859db5ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:12.756301Z",
     "start_time": "2025-06-30T06:16:12.749100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 7,  ..., 4, 5, 3])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4194])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n",
    "x_train\n",
    "print(y_train)\n",
    "print(type(y_train))\n",
    "print(type(x_train))\n",
    "x_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "244eb68a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:13.187596Z",
     "start_time": "2025-06-30T06:16:13.181463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4194, 12288])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f43a8ee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:13.643517Z",
     "start_time": "2025-06-30T06:16:13.638463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba29c072",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:16:15.980150Z",
     "start_time": "2025-06-30T06:16:14.035456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0039, 0.0078, 0.0118, 0.0157, 0.0196, 0.0235, 0.0275, 0.0314,\n",
       "        0.0353, 0.0392, 0.0431, 0.0471, 0.0510, 0.0549, 0.0588, 0.0627, 0.0667,\n",
       "        0.0706, 0.0745, 0.0784, 0.0824, 0.0863, 0.0902, 0.0941, 0.0980, 0.1020,\n",
       "        0.1059, 0.1098, 0.1137, 0.1176, 0.1216, 0.1255, 0.1294, 0.1333, 0.1373,\n",
       "        0.1412, 0.1451, 0.1490, 0.1529, 0.1569, 0.1608, 0.1647, 0.1686, 0.1725,\n",
       "        0.1765, 0.1804, 0.1843, 0.1882, 0.1922, 0.1961, 0.2000, 0.2039, 0.2078,\n",
       "        0.2118, 0.2157, 0.2196, 0.2235, 0.2275, 0.2314, 0.2353, 0.2392, 0.2431,\n",
       "        0.2471, 0.2510, 0.2549, 0.2588, 0.2627, 0.2667, 0.2706, 0.2745, 0.2784,\n",
       "        0.2824, 0.2863, 0.2902, 0.2941, 0.2980, 0.3020, 0.3059, 0.3098, 0.3137,\n",
       "        0.3176, 0.3216, 0.3255, 0.3294, 0.3333, 0.3373, 0.3412, 0.3451, 0.3490,\n",
       "        0.3529, 0.3569, 0.3608, 0.3647, 0.3686, 0.3725, 0.3765, 0.3804, 0.3843,\n",
       "        0.3882, 0.3922, 0.3961, 0.4000, 0.4039, 0.4078, 0.4118, 0.4157, 0.4196,\n",
       "        0.4235, 0.4275, 0.4314, 0.4353, 0.4392, 0.4431, 0.4471, 0.4510, 0.4549,\n",
       "        0.4588, 0.4627, 0.4667, 0.4706, 0.4745, 0.4784, 0.4824, 0.4863, 0.4902,\n",
       "        0.4941, 0.4980, 0.5020, 0.5059, 0.5098, 0.5137, 0.5176, 0.5216, 0.5255,\n",
       "        0.5294, 0.5333, 0.5373, 0.5412, 0.5451, 0.5490, 0.5529, 0.5569, 0.5608,\n",
       "        0.5647, 0.5686, 0.5725, 0.5765, 0.5804, 0.5843, 0.5882, 0.5922, 0.5961,\n",
       "        0.6000, 0.6039, 0.6078, 0.6118, 0.6157, 0.6196, 0.6235, 0.6275, 0.6314,\n",
       "        0.6353, 0.6392, 0.6431, 0.6471, 0.6510, 0.6549, 0.6588, 0.6627, 0.6667,\n",
       "        0.6706, 0.6745, 0.6784, 0.6824, 0.6863, 0.6902, 0.6941, 0.6980, 0.7020,\n",
       "        0.7059, 0.7098, 0.7137, 0.7176, 0.7216, 0.7255, 0.7294, 0.7333, 0.7373,\n",
       "        0.7412, 0.7451, 0.7490, 0.7529, 0.7569, 0.7608, 0.7647, 0.7686, 0.7725,\n",
       "        0.7765, 0.7804, 0.7843, 0.7882, 0.7922, 0.7961, 0.8000, 0.8039, 0.8078,\n",
       "        0.8118, 0.8157, 0.8196, 0.8235, 0.8275, 0.8314, 0.8353, 0.8392, 0.8431,\n",
       "        0.8471, 0.8510, 0.8549, 0.8588, 0.8627, 0.8667, 0.8706, 0.8745, 0.8784,\n",
       "        0.8824, 0.8863, 0.8902, 0.8941, 0.8980, 0.9020, 0.9059, 0.9098, 0.9137,\n",
       "        0.9176, 0.9216, 0.9255, 0.9294, 0.9333, 0.9373, 0.9412, 0.9451, 0.9490,\n",
       "        0.9529, 0.9569, 0.9608, 0.9647, 0.9686, 0.9725, 0.9765, 0.9804, 0.9843,\n",
       "        0.9882, 0.9922, 0.9961, 1.0000])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36c92272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:19:42.116261Z",
     "start_time": "2025-06-30T06:17:46.085285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iter 0 | W1 max: 0.2308, min: -0.2396\n",
      "Iter 0 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 0 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 1\n",
      "Iter 1 | W1 max: 0.2308, min: -0.2396\n",
      "Iter 1 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 1 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 2\n",
      "Iter 2 | W1 max: 0.2308, min: -0.2396\n",
      "Iter 2 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 2 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 3\n",
      "Iter 3 | W1 max: 0.2308, min: -0.2396\n",
      "Iter 3 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 3 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 4\n",
      "Iter 4 | W1 max: 0.2308, min: -0.2396\n",
      "Iter 4 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 4 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 5\n",
      "Iter 5 | W1 max: 0.2308, min: -0.2396\n",
      "Iter 5 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 5 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 6\n",
      "Iter 6 | W1 max: 0.2308, min: -0.2396\n",
      "Iter 6 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 6 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 7\n",
      "Iter 7 | W1 max: 0.2308, min: -0.2396\n",
      "Iter 7 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 7 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 8\n",
      "Iter 8 | W1 max: 0.2308, min: -0.2396\n",
      "Iter 8 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 8 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9\n",
      "Iter 9 | W1 max: 0.2307, min: -0.2396\n",
      "Iter 9 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 9 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 10\n",
      "Iter 10 | W1 max: 0.2307, min: -0.2396\n",
      "Iter 10 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 10 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 11\n",
      "Iter 11 | W1 max: 0.2307, min: -0.2396\n",
      "Iter 11 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 11 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 12\n",
      "Iter 12 | W1 max: 0.2307, min: -0.2396\n",
      "Iter 12 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 12 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 13\n",
      "Iter 13 | W1 max: 0.2307, min: -0.2396\n",
      "Iter 13 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 13 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 14\n",
      "Iter 14 | W1 max: 0.2307, min: -0.2396\n",
      "Iter 14 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 14 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 15\n",
      "Iter 15 | W1 max: 0.2307, min: -0.2396\n",
      "Iter 15 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 15 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 16\n",
      "Iter 16 | W1 max: 0.2307, min: -0.2397\n",
      "Iter 16 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 16 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 17\n",
      "Iter 17 | W1 max: 0.2307, min: -0.2397\n",
      "Iter 17 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 17 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18\n",
      "Iter 18 | W1 max: 0.2306, min: -0.2397\n",
      "Iter 18 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 18 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 19\n",
      "Iter 19 | W1 max: 0.2306, min: -0.2397\n",
      "Iter 19 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 19 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 20\n",
      "Iter 20 | W1 max: 0.2306, min: -0.2397\n",
      "Iter 20 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 20 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 21\n",
      "Iter 21 | W1 max: 0.2306, min: -0.2397\n",
      "Iter 21 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 21 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 22\n",
      "Iter 22 | W1 max: 0.2306, min: -0.2397\n",
      "Iter 22 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 22 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 23\n",
      "Iter 23 | W1 max: 0.2306, min: -0.2397\n",
      "Iter 23 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 23 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 24\n",
      "Iter 24 | W1 max: 0.2306, min: -0.2397\n",
      "Iter 24 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 24 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 25\n",
      "Iter 25 | W1 max: 0.2305, min: -0.2397\n",
      "Iter 25 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 25 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 26\n",
      "Iter 26 | W1 max: 0.2305, min: -0.2397\n",
      "Iter 26 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 26 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27\n",
      "Iter 27 | W1 max: 0.2305, min: -0.2397\n",
      "Iter 27 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 27 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 28\n",
      "Iter 28 | W1 max: 0.2305, min: -0.2397\n",
      "Iter 28 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 28 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 29\n",
      "Iter 29 | W1 max: 0.2305, min: -0.2397\n",
      "Iter 29 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 29 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 30\n",
      "Iter 30 | W1 max: 0.2305, min: -0.2397\n",
      "Iter 30 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 30 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 31\n",
      "Iter 31 | W1 max: 0.2304, min: -0.2397\n",
      "Iter 31 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 31 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 32\n",
      "Iter 32 | W1 max: 0.2304, min: -0.2397\n",
      "Iter 32 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 32 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 33\n",
      "Iter 33 | W1 max: 0.2304, min: -0.2397\n",
      "Iter 33 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 33 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 34\n",
      "Iter 34 | W1 max: 0.2304, min: -0.2397\n",
      "Iter 34 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 34 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 35\n",
      "Iter 35 | W1 max: 0.2304, min: -0.2397\n",
      "Iter 35 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 35 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36\n",
      "Iter 36 | W1 max: 0.2303, min: -0.2397\n",
      "Iter 36 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 36 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 37\n",
      "Iter 37 | W1 max: 0.2303, min: -0.2397\n",
      "Iter 37 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 37 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 38\n",
      "Iter 38 | W1 max: 0.2303, min: -0.2397\n",
      "Iter 38 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 38 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 39\n",
      "Iter 39 | W1 max: 0.2303, min: -0.2397\n",
      "Iter 39 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 39 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 40\n",
      "Iter 40 | W1 max: 0.2303, min: -0.2397\n",
      "Iter 40 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 40 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 41\n",
      "Iter 41 | W1 max: 0.2302, min: -0.2397\n",
      "Iter 41 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 41 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 42\n",
      "Iter 42 | W1 max: 0.2302, min: -0.2397\n",
      "Iter 42 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 42 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 43\n",
      "Iter 43 | W1 max: 0.2302, min: -0.2397\n",
      "Iter 43 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 43 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 44\n",
      "Iter 44 | W1 max: 0.2302, min: -0.2397\n",
      "Iter 44 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 44 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45\n",
      "Iter 45 | W1 max: 0.2301, min: -0.2396\n",
      "Iter 45 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 45 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 46\n",
      "Iter 46 | W1 max: 0.2301, min: -0.2396\n",
      "Iter 46 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 46 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 47\n",
      "Iter 47 | W1 max: 0.2301, min: -0.2396\n",
      "Iter 47 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 47 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 48\n",
      "Iter 48 | W1 max: 0.2301, min: -0.2396\n",
      "Iter 48 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 48 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 49\n",
      "Iter 49 | W1 max: 0.2300, min: -0.2396\n",
      "Iter 49 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 49 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 50\n",
      "Iter 50 | W1 max: 0.2300, min: -0.2396\n",
      "Iter 50 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 50 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 51\n",
      "Iter 51 | W1 max: 0.2300, min: -0.2396\n",
      "Iter 51 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 51 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 52\n",
      "Iter 52 | W1 max: 0.2300, min: -0.2396\n",
      "Iter 52 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 52 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 53\n",
      "Iter 53 | W1 max: 0.2299, min: -0.2396\n",
      "Iter 53 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 53 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 54\n",
      "Iter 54 | W1 max: 0.2299, min: -0.2396\n",
      "Iter 54 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 54 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 55\n",
      "Iter 55 | W1 max: 0.2299, min: -0.2396\n",
      "Iter 55 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 55 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 56\n",
      "Iter 56 | W1 max: 0.2299, min: -0.2396\n",
      "Iter 56 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 56 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 57\n",
      "Iter 57 | W1 max: 0.2298, min: -0.2396\n",
      "Iter 57 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 57 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 58\n",
      "Iter 58 | W1 max: 0.2298, min: -0.2396\n",
      "Iter 58 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 58 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 59\n",
      "Iter 59 | W1 max: 0.2298, min: -0.2396\n",
      "Iter 59 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 59 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 60\n",
      "Iter 60 | W1 max: 0.2297, min: -0.2396\n",
      "Iter 60 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 60 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 61\n",
      "Iter 61 | W1 max: 0.2297, min: -0.2395\n",
      "Iter 61 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 61 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 62\n",
      "Iter 62 | W1 max: 0.2297, min: -0.2395\n",
      "Iter 62 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 62 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 63\n",
      "Iter 63 | W1 max: 0.2296, min: -0.2395\n",
      "Iter 63 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 63 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 64\n",
      "Iter 64 | W1 max: 0.2296, min: -0.2395\n",
      "Iter 64 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 64 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 65\n",
      "Iter 65 | W1 max: 0.2296, min: -0.2395\n",
      "Iter 65 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 65 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 66\n",
      "Iter 66 | W1 max: 0.2296, min: -0.2395\n",
      "Iter 66 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 66 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 67\n",
      "Iter 67 | W1 max: 0.2295, min: -0.2395\n",
      "Iter 67 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 67 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 68\n",
      "Iter 68 | W1 max: 0.2295, min: -0.2395\n",
      "Iter 68 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 68 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 69\n",
      "Iter 69 | W1 max: 0.2295, min: -0.2395\n",
      "Iter 69 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 69 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 70\n",
      "Iter 70 | W1 max: 0.2294, min: -0.2394\n",
      "Iter 70 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 70 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 71\n",
      "Iter 71 | W1 max: 0.2294, min: -0.2394\n",
      "Iter 71 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 71 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 72\n",
      "Iter 72 | W1 max: 0.2294, min: -0.2394\n",
      "Iter 72 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 72 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 73\n",
      "Iter 73 | W1 max: 0.2293, min: -0.2394\n",
      "Iter 73 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 73 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 74\n",
      "Iter 74 | W1 max: 0.2293, min: -0.2394\n",
      "Iter 74 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 74 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 75\n",
      "Iter 75 | W1 max: 0.2293, min: -0.2394\n",
      "Iter 75 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 75 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 76\n",
      "Iter 76 | W1 max: 0.2292, min: -0.2394\n",
      "Iter 76 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 76 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 77\n",
      "Iter 77 | W1 max: 0.2292, min: -0.2394\n",
      "Iter 77 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 77 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 78\n",
      "Iter 78 | W1 max: 0.2292, min: -0.2393\n",
      "Iter 78 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 78 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 79\n",
      "Iter 79 | W1 max: 0.2291, min: -0.2393\n",
      "Iter 79 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 79 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 80\n",
      "Iter 80 | W1 max: 0.2307, min: -0.2393\n",
      "Iter 80 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 80 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 81\n",
      "Iter 81 | W1 max: 0.2326, min: -0.2393\n",
      "Iter 81 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 81 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 82\n",
      "Iter 82 | W1 max: 0.2345, min: -0.2393\n",
      "Iter 82 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 82 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 83\n",
      "Iter 83 | W1 max: 0.2365, min: -0.2393\n",
      "Iter 83 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 83 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 84\n",
      "Iter 84 | W1 max: 0.2385, min: -0.2392\n",
      "Iter 84 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 84 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 85\n",
      "Iter 85 | W1 max: 0.2406, min: -0.2392\n",
      "Iter 85 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 85 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 86\n",
      "Iter 86 | W1 max: 0.2427, min: -0.2392\n",
      "Iter 86 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 86 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 87\n",
      "Iter 87 | W1 max: 0.2448, min: -0.2392\n",
      "Iter 87 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 87 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 88\n",
      "Iter 88 | W1 max: 0.2470, min: -0.2392\n",
      "Iter 88 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 88 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 89\n",
      "Iter 89 | W1 max: 0.2492, min: -0.2392\n",
      "Iter 89 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 89 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 90\n",
      "Iter 90 | W1 max: 0.2515, min: -0.2391\n",
      "Iter 90 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 90 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 91\n",
      "Iter 91 | W1 max: 0.2538, min: -0.2391\n",
      "Iter 91 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 91 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 92\n",
      "Iter 92 | W1 max: 0.2561, min: -0.2391\n",
      "Iter 92 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 92 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 93\n",
      "Iter 93 | W1 max: 0.2585, min: -0.2391\n",
      "Iter 93 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 93 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 94\n",
      "Iter 94 | W1 max: 0.2610, min: -0.2391\n",
      "Iter 94 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 94 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 95\n",
      "Iter 95 | W1 max: 0.2635, min: -0.2390\n",
      "Iter 95 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 95 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 96\n",
      "Iter 96 | W1 max: 0.2660, min: -0.2390\n",
      "Iter 96 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 96 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 97\n",
      "Iter 97 | W1 max: 0.2686, min: -0.2390\n",
      "Iter 97 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 97 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 98\n",
      "Iter 98 | W1 max: 0.2712, min: -0.2390\n",
      "Iter 98 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 98 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99\n",
      "Iter 99 | W1 max: 0.2748, min: -0.2390\n",
      "Iter 99 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 99 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 100\n",
      "Iter 100 | W1 max: 0.2785, min: -0.2389\n",
      "Iter 100 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 100 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 101\n",
      "Iter 101 | W1 max: 0.2823, min: -0.2389\n",
      "Iter 101 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 101 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 102\n",
      "Iter 102 | W1 max: 0.2861, min: -0.2389\n",
      "Iter 102 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 102 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 103\n",
      "Iter 103 | W1 max: 0.2900, min: -0.2389\n",
      "Iter 103 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 103 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 104\n",
      "Iter 104 | W1 max: 0.2940, min: -0.2389\n",
      "Iter 104 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 104 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 105\n",
      "Iter 105 | W1 max: 0.2981, min: -0.2388\n",
      "Iter 105 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 105 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 106\n",
      "Iter 106 | W1 max: 0.3022, min: -0.2388\n",
      "Iter 106 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 106 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 107\n",
      "Iter 107 | W1 max: 0.3064, min: -0.2388\n",
      "Iter 107 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 107 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 108\n",
      "Iter 108 | W1 max: 0.3107, min: -0.2388\n",
      "Iter 108 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 108 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 109\n",
      "Iter 109 | W1 max: 0.3150, min: -0.2387\n",
      "Iter 109 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 109 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 110\n",
      "Iter 110 | W1 max: 0.3194, min: -0.2387\n",
      "Iter 110 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 110 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 111\n",
      "Iter 111 | W1 max: 0.3239, min: -0.2387\n",
      "Iter 111 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 111 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 112\n",
      "Iter 112 | W1 max: 0.3285, min: -0.2387\n",
      "Iter 112 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 112 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 113\n",
      "Iter 113 | W1 max: 0.3332, min: -0.2386\n",
      "Iter 113 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 113 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 114\n",
      "Iter 114 | W1 max: 0.3379, min: -0.2386\n",
      "Iter 114 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 114 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 115\n",
      "Iter 115 | W1 max: 0.3427, min: -0.2386\n",
      "Iter 115 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 115 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 116\n",
      "Iter 116 | W1 max: 0.3476, min: -0.2385\n",
      "Iter 116 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 116 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 117\n",
      "Iter 117 | W1 max: 0.3526, min: -0.2385\n",
      "Iter 117 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 117 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 118\n",
      "Iter 118 | W1 max: 0.3577, min: -0.2385\n",
      "Iter 118 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 118 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 119\n",
      "Iter 119 | W1 max: 0.3629, min: -0.2385\n",
      "Iter 119 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 119 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 120\n",
      "Iter 120 | W1 max: 0.3681, min: -0.2384\n",
      "Iter 120 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 120 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 121\n",
      "Iter 121 | W1 max: 0.3734, min: -0.2384\n",
      "Iter 121 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 121 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 122\n",
      "Iter 122 | W1 max: 0.3789, min: -0.2384\n",
      "Iter 122 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 122 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 123\n",
      "Iter 123 | W1 max: 0.3844, min: -0.2383\n",
      "Iter 123 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 123 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 124\n",
      "Iter 124 | W1 max: 0.3900, min: -0.2383\n",
      "Iter 124 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 124 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 125\n",
      "Iter 125 | W1 max: 0.3957, min: -0.2383\n",
      "Iter 125 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 125 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 126\n",
      "Iter 126 | W1 max: 0.4015, min: -0.2383\n",
      "Iter 126 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 126 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 127\n",
      "Iter 127 | W1 max: 0.4074, min: -0.2382\n",
      "Iter 127 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 127 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 128\n",
      "Iter 128 | W1 max: 0.4133, min: -0.2382\n",
      "Iter 128 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 128 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 129\n",
      "Iter 129 | W1 max: 0.4194, min: -0.2382\n",
      "Iter 129 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 129 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 130\n",
      "Iter 130 | W1 max: 0.4256, min: -0.2381\n",
      "Iter 130 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 130 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 131\n",
      "Iter 131 | W1 max: 0.4319, min: -0.2381\n",
      "Iter 131 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 131 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 132\n",
      "Iter 132 | W1 max: 0.4383, min: -0.2381\n",
      "Iter 132 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 132 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 133\n",
      "Iter 133 | W1 max: 0.4448, min: -0.2380\n",
      "Iter 133 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 133 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 134\n",
      "Iter 134 | W1 max: 0.4513, min: -0.2380\n",
      "Iter 134 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 134 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 135\n",
      "Iter 135 | W1 max: 0.4580, min: -0.2380\n",
      "Iter 135 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 135 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 136\n",
      "Iter 136 | W1 max: 0.4648, min: -0.2379\n",
      "Iter 136 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 136 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 137\n",
      "Iter 137 | W1 max: 0.4717, min: -0.2379\n",
      "Iter 137 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 137 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 138\n",
      "Iter 138 | W1 max: 0.4788, min: -0.2378\n",
      "Iter 138 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 138 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 139\n",
      "Iter 139 | W1 max: 0.4859, min: -0.2378\n",
      "Iter 139 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 139 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 140\n",
      "Iter 140 | W1 max: 0.4931, min: -0.2378\n",
      "Iter 140 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 140 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 141\n",
      "Iter 141 | W1 max: 0.5010, min: -0.2377\n",
      "Iter 141 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 141 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 142\n",
      "Iter 142 | W1 max: 0.5090, min: -0.2377\n",
      "Iter 142 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 142 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 143\n",
      "Iter 143 | W1 max: 0.5172, min: -0.2377\n",
      "Iter 143 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 143 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 144\n",
      "Iter 144 | W1 max: 0.5254, min: -0.2376\n",
      "Iter 144 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 144 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 145\n",
      "Iter 145 | W1 max: 0.5338, min: -0.2376\n",
      "Iter 145 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 145 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 146\n",
      "Iter 146 | W1 max: 0.5423, min: -0.2375\n",
      "Iter 146 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 146 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 147\n",
      "Iter 147 | W1 max: 0.5510, min: -0.2375\n",
      "Iter 147 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 147 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 148\n",
      "Iter 148 | W1 max: 0.5598, min: -0.2375\n",
      "Iter 148 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 148 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 149\n",
      "Iter 149 | W1 max: 0.5687, min: -0.2374\n",
      "Iter 149 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 149 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 150\n",
      "Iter 150 | W1 max: 0.5777, min: -0.2374\n",
      "Iter 150 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 150 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 151\n",
      "Iter 151 | W1 max: 0.5869, min: -0.2373\n",
      "Iter 151 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 151 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 152\n",
      "Iter 152 | W1 max: 0.5962, min: -0.2373\n",
      "Iter 152 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 152 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 153\n",
      "Iter 153 | W1 max: 0.6056, min: -0.2372\n",
      "Iter 153 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 153 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 154\n",
      "Iter 154 | W1 max: 0.6152, min: -0.2372\n",
      "Iter 154 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 154 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 155\n",
      "Iter 155 | W1 max: 0.6250, min: -0.2372\n",
      "Iter 155 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 155 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 156\n",
      "Iter 156 | W1 max: 0.6348, min: -0.2371\n",
      "Iter 156 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 156 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 157\n",
      "Iter 157 | W1 max: 0.6449, min: -0.2371\n",
      "Iter 157 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 157 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 158\n",
      "Iter 158 | W1 max: 0.6550, min: -0.2370\n",
      "Iter 158 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 158 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 159\n",
      "Iter 159 | W1 max: 0.6653, min: -0.2370\n",
      "Iter 159 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 159 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 160\n",
      "Iter 160 | W1 max: 0.6758, min: -0.2369\n",
      "Iter 160 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 160 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 161\n",
      "Iter 161 | W1 max: 0.6864, min: -0.2369\n",
      "Iter 161 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 161 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 162\n",
      "Iter 162 | W1 max: 0.6972, min: -0.2368\n",
      "Iter 162 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 162 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 163\n",
      "Iter 163 | W1 max: 0.7081, min: -0.2368\n",
      "Iter 163 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 163 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 164\n",
      "Iter 164 | W1 max: 0.7192, min: -0.2367\n",
      "Iter 164 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 164 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 165\n",
      "Iter 165 | W1 max: 0.7304, min: -0.2367\n",
      "Iter 165 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 165 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 166\n",
      "Iter 166 | W1 max: 0.7418, min: -0.2366\n",
      "Iter 166 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 166 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 167\n",
      "Iter 167 | W1 max: 0.7534, min: -0.2366\n",
      "Iter 167 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 167 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 168\n",
      "Iter 168 | W1 max: 0.7651, min: -0.2366\n",
      "Iter 168 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 168 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 169\n",
      "Iter 169 | W1 max: 0.7770, min: -0.2365\n",
      "Iter 169 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 169 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 170\n",
      "Iter 170 | W1 max: 0.7890, min: -0.2364\n",
      "Iter 170 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 170 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 171\n",
      "Iter 171 | W1 max: 0.8013, min: -0.2364\n",
      "Iter 171 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 171 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 172\n",
      "Iter 172 | W1 max: 0.8136, min: -0.2363\n",
      "Iter 172 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 172 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 173\n",
      "Iter 173 | W1 max: 0.8262, min: -0.2363\n",
      "Iter 173 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 173 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 174\n",
      "Iter 174 | W1 max: 0.8389, min: -0.2362\n",
      "Iter 174 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 174 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 175\n",
      "Iter 175 | W1 max: 0.8519, min: -0.2362\n",
      "Iter 175 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 175 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 176\n",
      "Iter 176 | W1 max: 0.8649, min: -0.2361\n",
      "Iter 176 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 176 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 177\n",
      "Iter 177 | W1 max: 0.8782, min: -0.2361\n",
      "Iter 177 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 177 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 178\n",
      "Iter 178 | W1 max: 0.8916, min: -0.2360\n",
      "Iter 178 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 178 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 179\n",
      "Iter 179 | W1 max: 0.9053, min: -0.2360\n",
      "Iter 179 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 179 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 180\n",
      "Iter 180 | W1 max: 0.9191, min: -0.2359\n",
      "Iter 180 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 180 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 181\n",
      "Iter 181 | W1 max: 0.9331, min: -0.2359\n",
      "Iter 181 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 181 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 182\n",
      "Iter 182 | W1 max: 0.9473, min: -0.2358\n",
      "Iter 182 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 182 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 183\n",
      "Iter 183 | W1 max: 0.9616, min: -0.2357\n",
      "Iter 183 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 183 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 184\n",
      "Iter 184 | W1 max: 0.9762, min: -0.2357\n",
      "Iter 184 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 184 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 185\n",
      "Iter 185 | W1 max: 0.9910, min: -0.2356\n",
      "Iter 185 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 185 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 186\n",
      "Iter 186 | W1 max: 1.0059, min: -0.2356\n",
      "Iter 186 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 186 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 187\n",
      "Iter 187 | W1 max: 1.0211, min: -0.2355\n",
      "Iter 187 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 187 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 188\n",
      "Iter 188 | W1 max: 1.0364, min: -0.2354\n",
      "Iter 188 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 188 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 189\n",
      "Iter 189 | W1 max: 1.0520, min: -0.2354\n",
      "Iter 189 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 189 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 190\n",
      "Iter 190 | W1 max: 1.0677, min: -0.2353\n",
      "Iter 190 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 190 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 191\n",
      "Iter 191 | W1 max: 1.0837, min: -0.2353\n",
      "Iter 191 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 191 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 192\n",
      "Iter 192 | W1 max: 1.0998, min: -0.2352\n",
      "Iter 192 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 192 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 193\n",
      "Iter 193 | W1 max: 1.1162, min: -0.2351\n",
      "Iter 193 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 193 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 194\n",
      "Iter 194 | W1 max: 1.1328, min: -0.2351\n",
      "Iter 194 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 194 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 195\n",
      "Iter 195 | W1 max: 1.1496, min: -0.2350\n",
      "Iter 195 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 195 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 196\n",
      "Iter 196 | W1 max: 1.1666, min: -0.2349\n",
      "Iter 196 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 196 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 197\n",
      "Iter 197 | W1 max: 1.1838, min: -0.2349\n",
      "Iter 197 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 197 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 198\n",
      "Iter 198 | W1 max: 1.2013, min: -0.2348\n",
      "Iter 198 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 198 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 199\n",
      "Iter 199 | W1 max: 1.2190, min: -0.2347\n",
      "Iter 199 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 199 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 200\n",
      "Iter 200 | W1 max: 1.2368, min: -0.2347\n",
      "Iter 200 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 200 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 201\n",
      "Iter 201 | W1 max: 1.2550, min: -0.2346\n",
      "Iter 201 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 201 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 202\n",
      "Iter 202 | W1 max: 1.2733, min: -0.2345\n",
      "Iter 202 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 202 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 203\n",
      "Iter 203 | W1 max: 1.2919, min: -0.2345\n",
      "Iter 203 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 203 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 204\n",
      "Iter 204 | W1 max: 1.3107, min: -0.2344\n",
      "Iter 204 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 204 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 205\n",
      "Iter 205 | W1 max: 1.3297, min: -0.2343\n",
      "Iter 205 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 205 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 206\n",
      "Iter 206 | W1 max: 1.3490, min: -0.2343\n",
      "Iter 206 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 206 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 207\n",
      "Iter 207 | W1 max: 1.3685, min: -0.2342\n",
      "Iter 207 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 207 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 208\n",
      "Iter 208 | W1 max: 1.3882, min: -0.2341\n",
      "Iter 208 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 208 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 209\n",
      "Iter 209 | W1 max: 1.4082, min: -0.2340\n",
      "Iter 209 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 209 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 210\n",
      "Iter 210 | W1 max: 1.4285, min: -0.2340\n",
      "Iter 210 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 210 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 211\n",
      "Iter 211 | W1 max: 1.4490, min: -0.2339\n",
      "Iter 211 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 211 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 212\n",
      "Iter 212 | W1 max: 1.4697, min: -0.2338\n",
      "Iter 212 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 212 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 213\n",
      "Iter 213 | W1 max: 1.4907, min: -0.2338\n",
      "Iter 213 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 213 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 214\n",
      "Iter 214 | W1 max: 1.5119, min: -0.2337\n",
      "Iter 214 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 214 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 215\n",
      "Iter 215 | W1 max: 1.5334, min: -0.2336\n",
      "Iter 215 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 215 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 216\n",
      "Iter 216 | W1 max: 1.5551, min: -0.2335\n",
      "Iter 216 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 216 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 217\n",
      "Iter 217 | W1 max: 1.5771, min: -0.2334\n",
      "Iter 217 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 217 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 218\n",
      "Iter 218 | W1 max: 1.5994, min: -0.2334\n",
      "Iter 218 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 218 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 219\n",
      "Iter 219 | W1 max: 1.6219, min: -0.2333\n",
      "Iter 219 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 219 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 220\n",
      "Iter 220 | W1 max: 1.6447, min: -0.2332\n",
      "Iter 220 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 220 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 221\n",
      "Iter 221 | W1 max: 1.6678, min: -0.2331\n",
      "Iter 221 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 221 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 222\n",
      "Iter 222 | W1 max: 1.6911, min: -0.2330\n",
      "Iter 222 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 222 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 223\n",
      "Iter 223 | W1 max: 1.7147, min: -0.2330\n",
      "Iter 223 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 223 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 224\n",
      "Iter 224 | W1 max: 1.7386, min: -0.2329\n",
      "Iter 224 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 224 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 225\n",
      "Iter 225 | W1 max: 1.7628, min: -0.2328\n",
      "Iter 225 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 225 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 226\n",
      "Iter 226 | W1 max: 1.7872, min: -0.2327\n",
      "Iter 226 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 226 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 227\n",
      "Iter 227 | W1 max: 1.8119, min: -0.2326\n",
      "Iter 227 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 227 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 228\n",
      "Iter 228 | W1 max: 1.8369, min: -0.2325\n",
      "Iter 228 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 228 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 229\n",
      "Iter 229 | W1 max: 1.8622, min: -0.2325\n",
      "Iter 229 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 229 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 230\n",
      "Iter 230 | W1 max: 1.8878, min: -0.2324\n",
      "Iter 230 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 230 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 231\n",
      "Iter 231 | W1 max: 1.9137, min: -0.2323\n",
      "Iter 231 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 231 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 232\n",
      "Iter 232 | W1 max: 1.9398, min: -0.2322\n",
      "Iter 232 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 232 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 233\n",
      "Iter 233 | W1 max: 1.9663, min: -0.2321\n",
      "Iter 233 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 233 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 234\n",
      "Iter 234 | W1 max: 1.9931, min: -0.2320\n",
      "Iter 234 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 234 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 235\n",
      "Iter 235 | W1 max: 2.0201, min: -0.2319\n",
      "Iter 235 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 235 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 236\n",
      "Iter 236 | W1 max: 2.0475, min: -0.2318\n",
      "Iter 236 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 236 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 237\n",
      "Iter 237 | W1 max: 2.0752, min: -0.2318\n",
      "Iter 237 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 237 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 238\n",
      "Iter 238 | W1 max: 2.1031, min: -0.2317\n",
      "Iter 238 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 238 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n",
      "Iteration 239\n",
      "Iter 239 | W1 max: 2.1314, min: -0.2316\n",
      "Iter 239 | A3 max: 0.9715, min: 0.0000, sum: 4193.999993538593\n",
      "Iter 239 | Predictions unique: (tensor([0, 1, 3, 4]), tensor([3538,   13,  601,   42]))\n",
      "Coba :tensor([[5.6037e-01, 3.2826e-01, 5.4304e-01,  ..., 5.1725e-01, 3.0481e-01,\n",
      "         3.1042e-01],\n",
      "        [2.8578e-02, 2.2657e-01, 9.5038e-02,  ..., 4.5599e-02, 1.1251e-01,\n",
      "         5.1015e-02],\n",
      "        [5.4304e-03, 4.0177e-04, 6.5789e-04,  ..., 2.6236e-03, 8.7810e-03,\n",
      "         4.8612e-03],\n",
      "        ...,\n",
      "        [7.1051e-03, 8.0287e-02, 4.5890e-02,  ..., 4.3268e-02, 5.7823e-02,\n",
      "         1.6525e-02],\n",
      "        [9.7819e-03, 5.1420e-03, 5.8889e-03,  ..., 5.5807e-03, 9.6954e-03,\n",
      "         1.8936e-02],\n",
      "        [1.6820e-03, 1.4934e-03, 2.6217e-03,  ..., 3.4366e-03, 2.7582e-03,\n",
      "         1.0752e-02]], dtype=torch.float64) dan predict : tensor([0, 1, 3, 4])\n",
      "Prediction: tensor([0, 0, 0,  ..., 0, 3, 3]), Label : tensor([1, 8, 4,  ..., 4, 4, 2])\n",
      "accuracy : 3.3528645038604736 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m train \u001b[38;5;241m=\u001b[39m Training(x_train,y_train)\n\u001b[1;32m----> 2\u001b[0m w1,b1,w2,b2,w3,b3\u001b[38;5;241m=\u001b[39mtrain\u001b[38;5;241m.\u001b[39mtrainingData()\n\u001b[0;32m      3\u001b[0m w1,b1,w2,b2,w3,b3\n",
      "Cell \u001b[1;32mIn[80], line 55\u001b[0m, in \u001b[0;36mTraining.trainingData\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch):\n\u001b[0;32m     54\u001b[0m     Z1,A1,Z2,A2,Z3,A3\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_prop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw2,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw3,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb3,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train)\n\u001b[1;32m---> 55\u001b[0m     dW1, db1, dW2, db2,dW3,db3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward_prop(Z1, A1, Z2, A2, A3, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw2,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw3,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw3,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw3,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb3, dW1, db1, dW2, db2,dW3,db3, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[80], line 31\u001b[0m, in \u001b[0;36mTraining.backward_prop\u001b[1;34m(self, Z1, A1, Z2, A2, A3, W1, W2, W3, X, Y)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward_prop\u001b[39m(\u001b[38;5;28mself\u001b[39m,Z1, A1, Z2, A2, A3,W1,W2,W3, X, Y):\n\u001b[1;32m---> 31\u001b[0m     dW, db, dW2, db2, dW3, db3\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbackPropLayer3(Z1, A1, Z2, A2, A3,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw2,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw3, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvertY(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(dW), torch\u001b[38;5;241m.\u001b[39mtensor(db), torch\u001b[38;5;241m.\u001b[39mtensor(dW2), torch\u001b[38;5;241m.\u001b[39mtensor(db2),torch\u001b[38;5;241m.\u001b[39mtensor(dW3), torch\u001b[38;5;241m.\u001b[39mtensor(db3)\n",
      "Cell \u001b[1;32mIn[79], line 30\u001b[0m, in \u001b[0;36mNetwork.backPropLayer3\u001b[1;34m(self, Z1, A1, Z2, A2, A3, W1, W2, W3, X, Y, m)\u001b[0m\n\u001b[0;32m     28\u001b[0m dW \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mm) \u001b[38;5;241m*\u001b[39m A2\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m dZ3\n\u001b[0;32m     29\u001b[0m dB \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mm) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(dZ3, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackPropLayer2(dZ3,A1,Z1, A2,Z2,W1,W2,W3,X, Y,m,dW,dB)\n",
      "Cell \u001b[1;32mIn[79], line 36\u001b[0m, in \u001b[0;36mNetwork.backPropLayer2\u001b[1;34m(self, dZ3, A1, Z1, A2, Z2, W1, W2, W3, X, Y, m, dW3, db3)\u001b[0m\n\u001b[0;32m     34\u001b[0m dW \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mm) \u001b[38;5;241m*\u001b[39m A1\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m@\u001b[39m dZ2\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     35\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(dZ2)\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackPropLayer1(dZ2,dZ3,A1,Z1, A2,Z2,W1,W2,X, Y,m,dW3,db3,dW,db)\n",
      "Cell \u001b[1;32mIn[79], line 40\u001b[0m, in \u001b[0;36mNetwork.backPropLayer1\u001b[1;34m(self, dZ2, dZ3, A1, Z1, A2, Z2, W1, W2, X, Y, m, dW3, db3, dW2, db2)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackPropLayer1\u001b[39m(\u001b[38;5;28mself\u001b[39m,dZ2,dZ3,A1,Z1, A2,Z2,W1,W2,X, Y,m,dW3,db3,dW2,db2):\n\u001b[0;32m     39\u001b[0m     dZ1 \u001b[38;5;241m=\u001b[39m (dZ2\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;129m@W2\u001b[39m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mfloat()) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1\u001b[38;5;241m.\u001b[39mdRelu(Z1\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m---> 40\u001b[0m     dW \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mm) \u001b[38;5;241m*\u001b[39m X\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m@\u001b[39m dZ1\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     41\u001b[0m     db \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(dZ1)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dW, db, dW2, db2, dW3, db3\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = Training(x_train,y_train)\n",
    "w1,b1,w2,b2,w3,b3=train.trainingData()\n",
    "w1,b1,w2,b2,w3,b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ff7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
